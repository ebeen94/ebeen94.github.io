<!DOCTYPE HTML>
<!--
	Phantom by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Charlotte Choi</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="inner">

							<!-- Logo -->
								<a href="index.html" class="logo">
									<span class="title">Home</span>
								</a>

							<!-- Nav -->
								<nav>
									<ul>
										<li><a href="#menu">Menu</a></li>
									</ul>
								</nav>

						</div>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<h2>Menu</h2>
						<ul>
							<li><a href="index.html">Home</a></li>
							<li><a href="generic.html">About Me</a></li>

						</ul>
					</nav>

				<!-- Main -->
					<div id="main">
						<div class="inner">
							<h1>Exploring the mediating role of AI autonomy levels in perceptions of AI systems.</h1>
							<span class="image main"></span>

							<p> 
								I started this project out of my curiosity of ‘how much level of autonomy do people prefer in an artificial intelligence?’ There had already been a number of studies which sought to discover AI autonomy in life-critical domains, including autonomous driving, autonomous judicial judge, and autonomous medical physician. However, a scarce number of studies have addressed the autonomy levels of AI in a day-to-day situations. Hence, I decided to design and conduct an experimental survey to explore the roles of the autonomous levels in people’s perception of an AI. I picked a corporate setting in particular, where an AI reviewer with differing levels of autonomy screens the cover letters of the candidates and gives a score and a brief feedback.
							Through this experimental survey, I wanted to gain insight on:<br />
							<ul>
								<i><li>Relationship between attitude towards AI and trust in AI</i> <br />
								H1: There is a positive relationship between attitude towards AI and trust in AI.</li><br />
								<i><li>Mediating effects of levels of AI autonomy on Trust in AI</i><br />
								H2: Levels of AI autonomy has mediating effects on the relationship between attitude towards AI and trust in AI.<br />
								H2a: Greater autonomy level creates higher perceived credibility in the AI.<br />
								H2b: Greater autonomy level creates higher perceived fairness in the AI.<br />
								H2c: Greater autonomy level creates higher perceived usefulness in the AI.<br /></li><br />
								<i><li>General sense of how people perceive different levels of AI autonomy</i><br />
								Post experiment interviews</li>
							</ul>
							</p>
							<br />
							<h2>EXPERIMENT DESIGN</h2>
							<p>
								I designed and conducted an experiment in a style of a mock job-application process. I posted a survey recruitment post asking for participation by anyone who wish their cover-letters to be reviewed by an AI reviewer. The surveys were done in Google Form. The first survey asked questions regarding the independent variables(knowledge on AI, experiences in AI and attitude towards AI). 
								<br /><br />
								The survey also checked which autonomous level of the AI reviewer they prefer to be evaluated by. The levels ranged from 1 to 5, with 5 having full-autonomy. In order to eliminate potential bias of the presented order, half of the participants were presented with autonomy levels in the ascending order(1-5) and half were presented with the autonomy levels in the descending order(5-1) when choosing their preference of the autonomy levels. We employed attention check questions at the end of the survey to make sure participants did not randomly choose the levels. 
								<br /><br />
								Upon completion of the survey, participants were instructed to submit their cover letters for an evaluation. Within 24 hours, participants received an email containing an evaluation paper containing an evaluation score on 6 criteria and a brief feedback on their cover-letters. Same score and feedback was given out to all the participants. The email also included a link to the 2nd survey, which measured the dependent variables (perceived fairness, credibility, and usefulness of the AI reviewer.) 4,500KRW was awarded to each participant upon completion of the experiment.
								<br /><br />
							<h2>AUTONOMY LEVEL</h2>
							The design of the autonomy levels of the AI reviewer were adapted from the autonomy levels of the self-driving vehicles. This was due to the fact that AI autonomy levels have been most actively discussed within the self-driving domain. The autonomy levels of the self-driving agent comprise sense, plan and act. For this study, act was chosen to be the main focus because the study addresses AI autonomy levels in a corporate environment; physically sensing the surrounding environment and planning accordingly as in bodily activities were not considered to be as important as acting - in which output of the work gets produced. With this basis in mind, different ratio of tasks were allocated to AI and human according to different AI autonomy levels.
							<br /><br />
							Tasks consisted of 6 units of workload- 1)Plagiarism, 2)similarity to high performing employees, 3)similarity to previously accepted cover-letter, 4)sentence structure, 5)style and tone of writing, 6)position suitability. Task 1,2,3,6 were adapted from newspapers. Multiple articles noted that Korean corporations are using AI reviewers and AI interviewers to check for applicants' plagiarism, similarity to high performing employees and position suitability. Task 4,5 were adapted from linguistic science papers.
							<br /><br />
							The tasks were purposefully built into an even number, so that equal number of tasks can be allocated to different task-types: analytical and cognitive. Tasks such as evaluating plagiarism, similarity to high performing employees, similarity to previously accepted cover-letter data were categorized into analytical-type. Tasks such as sentence structure, style and tone of writing, task suitability were categorized into cognitive-type. The validity of the autonomy levels were tested through a pilot test with 10 participants.
							<br /><br />
							</p>
							<center>

										<img src="images/Autonomy_1.png" style="width:500px;height:300px;"/>

										<img src="images/Autonomy_2.png" style="width:500px;height:300px;"/>

										<img src="images/Autonomy_3.png" style="width:500px;height:300px;"/>

										<img src="images/Autonomy_4.png" style="width:500px;height:300px;"/>

										<img src="images/Autonomy_5.png" style="width:500px;height:300px;"/><br /><br /><br />

						    </center>

							<h2>QUESTIONNAIRE</h2>
							Independent variables measured factors believed to have influence on the moderating variable of AI autonomy level, including experience in AI reviewer/AI interviewer, experience and knowledge in AI, confidence in cover-letter, and attitude towards AI.
							Specific questions and the original form of the questions are shown in the following excel sheet.
							<br /><br />
							Dependent variables gauged participants' perceived credibility, usefulness and fairness of the AI reviewer.  Questions regarding experience and sincerity in the 'Source Credibility' construct were omitted due to potential ascription of anthropomorphism when translated into Korean. I created an additional question to Nguyen's scale of usefulness of feedback, because it only consisted of two questions. The added question was : 'The feedback made me think I should revise my work'. 
							<br /><br />
							<iframe src="https://docs.google.com/spreadsheets/d/e/2PACX-1vQo8fv4-Pb22ULC20SXoOqsMO0xrouv_s6lIQuYcCd2a3gj5_qICORPPAdYaH8zivS0I-SFrLvFhbEZ/pubhtml?widget=true&amp;headers=false" style="width:1300px;height:700px;"></iframe>
							<br /><br />
							FYI: Not enough participants were recruited to yield statistically significant results, so the analysis has been postponed for now.  

		
							<br /><br />
							<br /><br />
						
							</p>
                        
                        </div>
					</div>

				<!-- Footer -->
					<footer id="footer">
                        <div class="inner">
                            <ul class = "copyright">
                                <li> Charlotte Choi</li>
                                <li> <a href= "index.html"> https://ebeen94.github.io/</a></li>
                            </ul>
                        </div>

					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
